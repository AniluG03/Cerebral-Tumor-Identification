{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AniluG03/Cerebral-Tumor-Identification/blob/main/AI-CTI(without%20results).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Team 6**\n",
        "\n",
        "Ana Luisa Garza Diaz      1948335\n",
        "Lucia Garza Garza         1956237\n",
        "Carolina Franco Ramirez   1902496"
      ],
      "metadata": {
        "id": "oAIWBhwWUsT_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWCJwNIa8ssW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "xxKEAUFZ8wAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "n5Y76NKl8xin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mohamedhanyyy/chest-ctscan-images"
      ],
      "metadata": {
        "id": "RvAntmP88z8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o \"archive.zip\""
      ],
      "metadata": {
        "id": "LGY6SdI384aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorios de las categorías (se mantiene igual)\n",
        "folder_paths = {\n",
        "    'adenocarcinoma': 'Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib',\n",
        "    'large_cell_carcinoma': 'Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa',\n",
        "    'normal': 'Data/train/normal',\n",
        "    'squamous_cell_carcinoma': 'Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa'\n",
        "}\n",
        "\n",
        "# Función para visualizar imágenes\n",
        "def show_images(images, labels, rows=1, figsize=(15, 5), preprocessing=None):\n",
        "    \"\"\" Muestra imágenes con o sin preprocesamiento aplicado. \"\"\"\n",
        "    fig, axes = plt.subplots(rows, len(images) // rows, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    for img, ax, label in zip(images, axes, labels):\n",
        "        if preprocessing:\n",
        "            img = preprocessing(img)\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(label)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Cargar y etiquetar imágenes\n",
        "images = []\n",
        "labels = []\n",
        "class_names = ['adenocarcinoma', 'large_cell_carcinoma', 'normal', 'squamous_cell_carcinoma']\n",
        "\n",
        "for label, folder_path in folder_paths.items():\n",
        "    image_files = glob.glob(folder_path + '/*.png')\n",
        "    for image_file in image_files:\n",
        "        image = Image.open(image_file)\n",
        "        image = image.convert('RGB')  # Convierte la imagen a RGB si es necesario\n",
        "        image = image.resize((150, 150))  # Redimensiona la imagen\n",
        "        images.append(np.array(image))\n",
        "        labels.append(class_names.index(label))\n",
        "\n",
        "# Seleccionar algunas imágenes para mostrar antes del preprocesamiento\n",
        "sample_images = [images[i] for i in range(10)]\n",
        "sample_labels = [class_names[labels[i]] for i in range(10)]\n",
        "\n",
        "# Mostrar imágenes antes del preprocesamiento\n",
        "print(\"Images before preprocessing:\")\n",
        "show_images(sample_images, sample_labels, rows=1)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir a arrays de numpy y normalizar\n",
        "train_images = np.array(train_images) / 255.0\n",
        "test_images = np.array(test_images) / 255.0\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Definir función de preprocesamiento para normalización\n",
        "def preprocess_image(image):\n",
        "    image = np.array(image)\n",
        "    return image / 255.0  # Normalizar\n",
        "\n",
        "# Mostrar imágenes después del preprocesamiento\n",
        "print(\"Images after preprocessing:\")\n",
        "show_images(sample_images, sample_labels, rows=1, preprocessing=preprocess_image)"
      ],
      "metadata": {
        "id": "0dy8ADygkkDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir el modelo de la CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "id": "LY7ezQnvChIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la precisión y la pérdida durante el entrenamiento\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FjxHEsZ2Chvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_predictions(test_images, test_labels, predictions, num_images=30):\n",
        "    class_names = ['adenocarcinoma', 'large_cell_carcinoma', 'normal', 'squamous_cell_carcinoma']\n",
        "    correct_count = 0\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(num_images):\n",
        "        ax = plt.subplot(6, 5, i + 1)  # Ajusta las dimensiones para acomodar 30 imágenes\n",
        "        ax.imshow(test_images[i])\n",
        "        real_label = class_names[test_labels[i]]\n",
        "        predicted_label = class_names[np.argmax(predictions[i])]\n",
        "        is_correct = real_label == predicted_label\n",
        "        if is_correct:\n",
        "            correct_count += 1\n",
        "        percentage = round(np.max(predictions[i]) * 100, 2)\n",
        "\n",
        "        ax.set_title(f'True label: {real_label}\\nPredicted: {predicted_label} ({percentage}%)\\nCorrect: {\"True\" if is_correct else \"False\"}', color='green' if is_correct else 'red', fontsize=8)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    return correct_count\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Mostrar predicciones y obtener el conteo de aciertos\n",
        "correct_count = show_predictions(test_images, test_labels, predictions, num_images=30)\n",
        "\n",
        "# Calcular y mostrar el porcentaje de éxito global\n",
        "total_images = 30\n",
        "success_percentage = (correct_count / total_images) * 100\n",
        "print(f\"Porcentaje de éxito global: {success_percentage:.2f}%\")\n"
      ],
      "metadata": {
        "id": "k_vHgp84CnG5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}